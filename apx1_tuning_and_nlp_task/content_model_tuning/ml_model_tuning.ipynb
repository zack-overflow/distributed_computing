{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"uva_seal.png\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ML Model Selection and Tuning\n",
    "\n",
    "### University of Virginia\n",
    "### DS 7200: Distributed Computing\n",
    "### Last Updated: August 20, 2023\n",
    "\n",
    "---  \n",
    "\n",
    "\n",
    "### SOURCES\n",
    "- Learning Spark, Chapter 11: Machine Learning with MLlib  \n",
    "- https://spark.apache.org/docs/3.0.1/ml-tuning.html  \n",
    "\n",
    "\n",
    "\n",
    "### OBJECTIVES\n",
    "- Discuss cross validation  \n",
    "- Discuss hyperparameter tuning  \n",
    "- Discuss model evaluation  \n",
    "\n",
    "\n",
    "### CONCEPTS\n",
    "\n",
    "- Data Splitting  \n",
    "- Train/Validation/Test sets  \n",
    "- K-Fold Cross Validation  \n",
    "- CrossValidator  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Model Tuning\n",
    "\n",
    "Oftentimes, a model will include hyperparameters that need to be tuned for optimal performance.  \n",
    "\n",
    "We have seen many examples, such as the cost parameter in the support vector machine, and the   regularization parameter in L2 regression\n",
    "\n",
    "The optimal value of the hyperparameter cannot be determined in advance, as it depends on the data.  \n",
    "\n",
    "Before a model is trained on data, a plan should be made for *data splitting*.  The purpose of the data splitting step is to accomplish the following:  \n",
    "\n",
    "\n",
    "**1. Model Performance Evaluation**  \n",
    "Set aside a fraction of the data which has not been used for training or tuning.  This test set will be used to evaluate the performance of the model.  If the same data used in training/tuning is also used for evaluation, the results will be too optimistic.  \n",
    "\n",
    "**2. Training and Tuning**  \n",
    "After setting aside the test set, the remaining data will be used for training and tuning.  This train/validation data is often applied in a k-fold cross validation (cv) procedure.  We outline an example cv procedure below.  Typical values for $k$ (the number of folds) are 5 and 10.  \n",
    "\n",
    "The fractions used in the train/validation/test sets will vary depending on factors including the size of the dataset.  \n",
    "\n",
    "Additionally, some users may include more elaborate splitting schemes (e.g, extra validation sets or test sets), depending on the specific problem.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross Validation Illustration**  \n",
    "5-Fold Cross Validation with a Separate Test Set  \n",
    "The Training/Validation Sets are 80% of the data; each fold is 16% of the data.  \n",
    "The Test Set is 20% of the data.  \n",
    "\n",
    "<img src=\"cross_validation_img.png\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Implementation of Model Tuning\n",
    "\n",
    "First some quick definitions:  \n",
    "\n",
    "\n",
    "- `ParamMaps`: parameters to choose from, aka parameter grid\n",
    "- Estimator:   algorithm or `Pipeline` to tune\n",
    "- Evaluator: metric to measure how well a fitted Model does on held-out test data\n",
    "\n",
    "Tuning can be done on models or pipelines\n",
    "\n",
    "**Important Note:**  \n",
    "Spark validation set = our test set\n",
    "\n",
    "**Methods available for model selection:**  \n",
    "\n",
    "- `CrossValidator`\n",
    "\n",
    "- `TrainValidationSplit`\n",
    "\n",
    "### `CrossValidator`\n",
    "\n",
    "`CrossValidator` begins by splitting the dataset into a set of folds which are used as separate training and test datasets. E.g., with k=3 folds, `CrossValidator` will generate 3 (training, test) dataset pairs, each of which uses 2/3 of the data for training and 1/3 for testing. To evaluate a particular `ParamMap`, `CrossValidator` computes the average evaluation metric for the 3 Models produced by fitting the `Estimator` on the 3 different (training, test) dataset pairs.\n",
    "After identifying the best `ParamMap`, `CrossValidator` finally re-fits the `Estimator` using the best `ParamMap` and the entire dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`CrossValidator` Example**  \n",
    "[Source](https://spark.apache.org/docs/3.0.1/ml-tuning.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data\n",
      "+---+----------------+-----+\n",
      "| id|            text|label|\n",
      "+---+----------------+-----+\n",
      "|  0| a b c d e spark|  1.0|\n",
      "|  1|             b d|  0.0|\n",
      "|  2|     spark f g h|  1.0|\n",
      "|  3|hadoop mapreduce|  0.0|\n",
      "|  4|     b spark who|  1.0|\n",
      "+---+----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "type(training): <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "------------------------------\n",
      "paramGrid [{Param(parent='HashingTF_39b5f63b6f44', name='numFeatures', doc='Number of features. Should be greater than 0.'): 10, Param(parent='LogisticRegression_010fc459885a', name='regParam', doc='regularization parameter (>= 0).'): 0.1}, {Param(parent='HashingTF_39b5f63b6f44', name='numFeatures', doc='Number of features. Should be greater than 0.'): 10, Param(parent='LogisticRegression_010fc459885a', name='regParam', doc='regularization parameter (>= 0).'): 0.01}, {Param(parent='HashingTF_39b5f63b6f44', name='numFeatures', doc='Number of features. Should be greater than 0.'): 100, Param(parent='LogisticRegression_010fc459885a', name='regParam', doc='regularization parameter (>= 0).'): 0.1}, {Param(parent='HashingTF_39b5f63b6f44', name='numFeatures', doc='Number of features. Should be greater than 0.'): 100, Param(parent='LogisticRegression_010fc459885a', name='regParam', doc='regularization parameter (>= 0).'): 0.01}, {Param(parent='HashingTF_39b5f63b6f44', name='numFeatures', doc='Number of features. Should be greater than 0.'): 1000, Param(parent='LogisticRegression_010fc459885a', name='regParam', doc='regularization parameter (>= 0).'): 0.1}, {Param(parent='HashingTF_39b5f63b6f44', name='numFeatures', doc='Number of features. Should be greater than 0.'): 1000, Param(parent='LogisticRegression_010fc459885a', name='regParam', doc='regularization parameter (>= 0).'): 0.01}] \n",
      "\n",
      "len(paramGrid): 6\n",
      "------------------------------\n",
      "train time: 24.32192325592041\n",
      "------------------------------\n",
      "Row(id=4, text='spark i j k', probability=DenseVector([0.2661, 0.7339]), prediction=1.0)\n",
      "Row(id=5, text='l m n', probability=DenseVector([0.9209, 0.0791]), prediction=0.0)\n",
      "Row(id=6, text='mapreduce spark', probability=DenseVector([0.4429, 0.5571]), prediction=1.0)\n",
      "Row(id=7, text='apache hadoop', probability=DenseVector([0.8584, 0.1416]), prediction=0.0)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "spark= SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Prepare training documents, which are labeled 1 when text contains \"spark\", else 0\n",
    "training = spark.createDataFrame([\n",
    "    (0, \"a b c d e spark\", 1.0),\n",
    "    (1, \"b d\", 0.0),\n",
    "    (2, \"spark f g h\", 1.0),\n",
    "    (3, \"hadoop mapreduce\", 0.0),\n",
    "    (4, \"b spark who\", 1.0),\n",
    "    (5, \"g d a y\", 0.0),\n",
    "    (6, \"spark fly\", 1.0),\n",
    "    (7, \"was mapreduce\", 0.0),\n",
    "    (8, \"e spark program\", 1.0),\n",
    "    (9, \"a e c l\", 0.0),\n",
    "    (10, \"spark compile\", 1.0),\n",
    "    (11, \"hadoop software\", 0.0)\n",
    "], [\"id\", \"text\", \"label\"])\n",
    "\n",
    "\n",
    "print('training data')\n",
    "training.show(5)\n",
    "print('type(training): {}'.format(type(training)))\n",
    "\n",
    "# Configure an ML pipeline, which consists of three stages: tokenizer, hashingTF, and lr.\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=10)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n",
    "\n",
    "# Set up the parameter grid\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(hashingTF.numFeatures, [10, 100, 1000]) \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .build()\n",
    "\n",
    "print('-'*30)\n",
    "print('paramGrid', paramGrid, '\\n')\n",
    "print('len(paramGrid): {}'.format(len(paramGrid)))\n",
    "print('-'*30)\n",
    "\n",
    "# Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=2)\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "import time\n",
    "t0 = time.time()\n",
    "cvModel = crossval.setParallelism(4).fit(training) # train 4 models in parallel\n",
    "#cvModel = crossval.fit(training)\n",
    "print(\"train time:\", time.time() - t0)\n",
    "print('-'*30)\n",
    "\n",
    "# Prepare test documents, which are unlabeled.\n",
    "test = spark.createDataFrame([\n",
    "    (4, \"spark i j k\"),\n",
    "    (5, \"l m n\"),\n",
    "    (6, \"mapreduce spark\"),\n",
    "    (7, \"apache hadoop\")\n",
    "], [\"id\", \"text\"])\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "prediction = cvModel.transform(test)\n",
    "selected = prediction.select(\"id\", \"text\", \"probability\", \"prediction\")\n",
    "\n",
    "for row in selected.collect():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Optimization Tip**  \n",
    "For cross validation, *spark.ml* trains the models sequentially, not in parallel.\n",
    "In the code above, rather than using:\n",
    "\n",
    "```\n",
    "cvModel = crossval.fit(training)\n",
    "```\n",
    "\n",
    "the number of models to train in parallel is set like this:  \n",
    "\n",
    "```\n",
    "cvModel = crossval.setParallelism(4).fit(training)\n",
    "```  \n",
    "\n",
    "This resulted in a significant time savings of 33%.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `TrainValidationSplit`\n",
    "\n",
    "This method only performs one split (unlike the $k$ splits of `CrossValidator`).  \n",
    "Advantage: runtime is faster since the model is trained only once.  \n",
    "Disadvantage: results may not be as reliable out-of-sample if the training dataset isn’t sufficiently large  \n",
    "\n",
    "Method takes parameter `trainRatio`  \n",
    "\n",
    "For example, with `trainRatio` = 0.6, the train/test sets will be 60%/40% of the data, respectively  \n",
    "\n",
    "For an example, refer to documentation link under **Sources** section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRY FOR YOURSELF (UNGRADED EXERCISE)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) **`CrossValidator`**  \n",
    "i. Copy the `CrossValidator` example in the cell below  \n",
    "ii. Try a different estimator in place of logistic regression  \n",
    "iii. Modify the `ParamGridBuilder` to include the appropriate hyperparameters  \n",
    "iv. Train the `CrossValidator` and make predictions  \n",
    "v. Compute the accuracy.  How does it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "DS5110 Spark 3.3",
   "language": "python",
   "name": "ds5110_spark3.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
